{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import project_name_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = 'PLS_results'\n",
    "\n",
    "\n",
    "#Create path to store the PLS plots and data\n",
    "os.makedirs(working_dir, exist_ok=True)\n",
    "os.makedirs(working_dir+'/element', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/plots/hist_plot', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/plots/Lingress', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/plots/loading_plot', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/plots/s_plot', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/plots/score_plot', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/plots/VIP_score_plot', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/data/Permutation_scores', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/data/OPLS_scores', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/data/Loading_scores', exist_ok=True)\n",
    "os.makedirs(working_dir+'/element/data/VIP_scores', exist_ok=True)\n",
    "os.mkdir(working_dir+'/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = glob(working_dir + '/element/*/*/')\n",
    "\n",
    "#Create dictionary to store the path\n",
    "path = {}\n",
    "for i in dir:\n",
    "    path[i.split('/')[-2]] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_name_generator():\n",
    "    #random project name\n",
    "    #get random time\n",
    "    import random\n",
    "    import time\n",
    "    # Get local time\n",
    "    current_time = time.localtime()\n",
    "    # Set format for time\n",
    "    time_format = time.strftime('%Y-%m-%d %H:%M:%S', current_time)\n",
    "    project_names = [\n",
    "                    \"QuantumQuest\",\n",
    "                    \"NebulaNet\",\n",
    "                    \"StellarSync\",\n",
    "                    \"AeroPulse\",\n",
    "                    \"CyberCircuit\",\n",
    "                    \"TerraTrack\",\n",
    "                    \"HoloHive\",\n",
    "                    \"PyroPixel\",\n",
    "                    \"LunarLoom\",\n",
    "                    \"ZenithZero\",\n",
    "                    \"BlazeBeacon\",\n",
    "                    \"AquaArise\",\n",
    "                    \"EchoEclipse\",\n",
    "                    \"FusionForge\",\n",
    "                    \"OrbitOpus\",\n",
    "                    \"PrismPortal\",\n",
    "                    \"NimbusNexus\",\n",
    "                    \"AstroArc\",\n",
    "                    \"VoltVoyage\",\n",
    "                    \"OmniOrbit\",\n",
    "                    \"PulsePioneer\",\n",
    "                    \"VortexVoyage\",\n",
    "                    \"GalacticGrid\",\n",
    "                    \"SolarSpectrum\",\n",
    "                    \"Satternlite\",\n",
    "                    \"StarSpectrum\",\n",
    "                    \"SpaceSpectrum\",\n",
    "                    \"GalacticSpectrum\"\n",
    "                    ]\n",
    "\n",
    "    project_name = time_format + '_' + random.choice(project_names)\n",
    "    return project_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lazypair:\n",
    "\n",
    "\n",
    "    def __init__(self, dataset, column_name):\n",
    "        \n",
    "        meta = dataset\n",
    "        self.meta = meta\n",
    "        self.column_name = column_name\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        This function takes in a dataframe and a column name and returns the index of the dataframe and the names of the pairs\n",
    "        of the unique values in the column.\n",
    "        Parameters\n",
    "        ----------\n",
    "        meta: pandas dataframe\n",
    "            The dataframe to be used.\n",
    "        column_name: str\n",
    "        Unipair(meta, column_name).indexing()\n",
    "        \n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        #check unique values in the column\n",
    "        if meta[column_name].nunique() < 3:\n",
    "            raise ValueError(\"Group should contain at least 3 groups\")\n",
    "        else:\n",
    "            pass\n",
    "        #check meta is a dataframe\n",
    "        if not isinstance(meta, pd.DataFrame):\n",
    "            raise ValueError(\"meta should be a pandas dataframe\")\n",
    "        #check column_name is a string\n",
    "        if not isinstance(column_name, str):\n",
    "            raise ValueError(\"column_name should be a string\")\n",
    "        \n",
    "\n",
    "        df = meta\n",
    "        y = df[column_name].unique()\n",
    "        pairs = []\n",
    "        for i in range(len(y)):\n",
    "            for j in range(i+1, len(y)):\n",
    "                pairs.append([y[i], y[j]])\n",
    "        \n",
    "        index_ = []\n",
    "        for i in range(len(pairs)):\n",
    "            inside_index = []\n",
    "            for j in range(2):\n",
    "                inside_index.append(list((df.loc[df[column_name] == pairs[i][j]]).index))\n",
    "            index_list = [inside_index[0] + inside_index[1]]\n",
    "            index_.append(index_list[0])\n",
    "        pairs\n",
    "        index_\n",
    "        names = []\n",
    "        for i in range(len(pairs)):\n",
    "            \n",
    "            names.append(str(pairs[i][0]) + \"_vs_\" + str(pairs[i][1]))\n",
    "            #check names if contain / replace with _ \n",
    "            names[i] = names[i].replace('/', '_')\n",
    "            \n",
    "        del df\n",
    "        del y\n",
    "        \n",
    "        self.index_ = index_\n",
    "        self.names = names\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def get_index(self):\n",
    "        index_ = self.index_\n",
    "        return index_\n",
    "    \n",
    "    def get_name(self):\n",
    "        names = self.names\n",
    "        return names\n",
    "    \n",
    "    def get_meta(self):\n",
    "        meta = self.meta\n",
    "        column_name = self.column_name\n",
    "        return meta[column_name]\n",
    "    \n",
    "    def get_column_name(self):\n",
    "        column_name = self.column_name\n",
    "        return column_name\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        df = self.meta\n",
    "        index_ = self.index_\n",
    "        list_of_df = []\n",
    "        for i in range(len(index_)):\n",
    "            list_of_df.append(df.loc[index_[i]])\n",
    "        \n",
    "        #Create object attribute\n",
    "        self.list_of_df = list_of_df\n",
    "        return list_of_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lazy_opls_da:\n",
    "\n",
    "    \n",
    "    import os\n",
    "    from glob import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import random\n",
    "    from metbit import opls_da\n",
    "\n",
    "    from metbit import project_name_generator\n",
    "    \n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, groups: list, working_dir: str, n_components: int = 2, scaling: str = 'pareto', \n",
    "                    estimator: str = 'opls', kfold: int = 3, random_state: int = 94, auto_ncomp: bool = True,  \n",
    "                    permutation: bool = True, \n",
    "                    VIP: bool = True, \n",
    "                    linear_regression: bool = True) -> None:\n",
    "\n",
    "        self.groups = groups\n",
    "        self.n_components = n_components\n",
    "        self.working_dir = working_dir\n",
    "\n",
    "        self.random_state = random_state        \n",
    "        self.estimator = estimator\n",
    "        self.scale = scaling\n",
    "        self.kfold = kfold\n",
    "        self.auto_ncomp = auto_ncomp\n",
    "        \n",
    "\n",
    "        data['Class'] = groups\n",
    "        self.data = data\n",
    "\n",
    "        self.permutation = permutation\n",
    "        if permutation == True:\n",
    "            self.n_permutataion = int(input('Enter the number of permutation: '))\n",
    "            self.n_jobs = int(input('Enter the number of jobs: '))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        self.VIP = VIP\n",
    "        if VIP == True:\n",
    "            self.VIP_threshold = float(input('Enter the VIP threshold: '))\n",
    "\n",
    "        self.linear_regression = linear_regression\n",
    "        if linear_regression == True:\n",
    "            self.FC_threshold = float(input('Enter the fold change threshold: '))\n",
    "            self.p_val_threshold = float(input('Enter the p-value threshold: '))\n",
    "\n",
    "        \"\"\"\n",
    "        This function takes in a dataframe and a list of y values and returns the project_name model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pandas dataframe\n",
    "            The dataframe to be used.\n",
    "        y: list\n",
    "            The list of y values.\n",
    "        n_components: int\n",
    "            The number of components to use.\n",
    "        lazy_opls_da(data, y, n_components).fit()\n",
    "        \"\"\"\n",
    "        \n",
    "        project_name = project_name_generator()\n",
    "        \n",
    "\n",
    "        #Remove last / from working_dir\n",
    "        if working_dir[-1] == '/':\n",
    "            working_dir = working_dir[:-1]\n",
    "        else:\n",
    "            working_dir = working_dir\n",
    "\n",
    "        #Replace \\ with / for windows\n",
    "        working_dir = working_dir.replace('\\\\', '/')\n",
    "\n",
    "\n",
    "        if os.path.exists(working_dir + '/' + project_name + '/element'):\n",
    "            print('Directory already exist')\n",
    "        else:\n",
    "            folder_name_plot = ['loading_plot', 's_plot', 'score_plot']\n",
    "            folder_name_data = []\n",
    "            if permutation == True:\n",
    "                folder_name_plot.append('hist_plot')\n",
    "            else:\n",
    "                pass\n",
    "            if VIP == True:\n",
    "                folder_name_plot.append('VIP_score_plot')\n",
    "                folder_name_data.append('VIP_scores')\n",
    "            else:\n",
    "                pass\n",
    "            if linear_regression == True:\n",
    "                folder_name_plot.append('Volcano_plot')\n",
    "                folder_name_data.append('Lingress_data')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            os.makedirs(working_dir+'/' + project_name + '/element', exist_ok=True)\n",
    "            for i in folder_name_plot:\n",
    "                os.makedirs(working_dir+'/' + project_name + '/element/plots/' + i, exist_ok=True)\n",
    "            for i in folder_name_data:\n",
    "                os.makedirs(working_dir+'/' + project_name + '/element/data/' + i, exist_ok=True)\n",
    "\n",
    "            os.makedirs(working_dir+'/' + project_name + '/main')\n",
    "\n",
    "        #Create dictionary to store the path\n",
    "        dir = glob(working_dir + '/' + project_name + '/element/*/*/')\n",
    "\n",
    "        #Create dictionary to store the path\n",
    "        path = {}\n",
    "        for i in dir:\n",
    "            path[i.split('/')[-2]] = i\n",
    "\n",
    "        self.color_map = color_map\n",
    "        self.path = path\n",
    "\n",
    "        #Print summary model as table text format\n",
    "        Summary = f\"\"\"\n",
    "        Project Name: {project_name}\n",
    "        Number of groups: {len(data['Class'].unique())}\n",
    "        Number of samples: {len(data)}\n",
    "        Number of features: {len(data.columns) - 1}\n",
    "        Number of components: {n_components}\n",
    "        Estimator: {estimator}\n",
    "        Scaling: {scaling}\n",
    "        Kfold: {kfold}\n",
    "        Random state: {random_state}\n",
    "        Auto ncomp: {auto_ncomp}\n",
    "        Working directory: {working_dir}\n",
    "        Permutation: {permutation}\n",
    "        VIP: {VIP}\n",
    "        Linear regression: {linear_regression}\n",
    "        \"\"\"\n",
    "\n",
    "        return print(Summary)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, marker_color: dict = None) -> None:\n",
    "\n",
    "        from metbit import opls_da\n",
    "        from lingress import lin_regression\n",
    "        from metbit import lazypair\n",
    "\n",
    "     \n",
    "        data = self.data\n",
    "        n_components = self.n_components\n",
    "        path = self.path\n",
    "        color_map = self.color_map\n",
    "        scale = self.scale\n",
    "\n",
    "        marker_color = marker_color\n",
    "\n",
    "\n",
    "        #Create object attribute\n",
    "        lazy = lazypair(data, 'Class')\n",
    "        data_list = lazy.get_dataset()\n",
    "        name_save = lazy.get_name()\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            \n",
    "            df = data_list[i]\n",
    "            name = name_save[i]\n",
    "\n",
    "            X = df.drop('Class', axis=1)\n",
    "            y = df['Class']\n",
    "            feature_names = X.columns\n",
    "            # Check if feature names can be converted to float\n",
    "            try:\n",
    "                feature_names = feature_names(float).tolist()\n",
    "            except:\n",
    "                feature_names = feature_names.tolist()\n",
    "\n",
    "            #PLS\n",
    "            pls_mod = opls_da(X=X, y=y, features_name = feature_names, n_components=n_components, scale=scale, estimator=self.estimator, kfold=self.kfold, random_state=self.random_state, auto_ncomp = self.auto_ncomp)\n",
    "            pls_mod.fit()\n",
    "\n",
    "            #Score plot\n",
    "            pls_mod.plot_pls_scores(color_dict=marker_color).write_html(path['score_plot'] + name + '_score_plot.html')\n",
    "            pls_mod.plot_pls_scores(color_dict=marker_color).write_image(path['score_plot'] + name + '_score_plot.png')\n",
    "\n",
    "            #Loading plot\n",
    "            pls_mod.plot_loading().write_html(path['loading_plot'] + name + '_loading_plot.html')\n",
    "            pls_mod.plot_loading().write_image(path['loading_plot'] + name + '_loading_plot.png')\n",
    "\n",
    "            #S plot\n",
    "            pls_mod.plot_s_scores().write_html(path['s_plot'] + name + '_s_plot.html')\n",
    "            pls_mod.plot_s_scores().write_image(path['s_plot'] + name + '_s_plot.png')\n",
    "\n",
    "            #VIP score plot\n",
    "            if self.VIP == True:\n",
    "                pls_mod.vip_scores()\n",
    "                pls_mod.get_vip_scores().to_csv(path['VIP_scores'] + name + '_VIP_scores.csv')\n",
    "                pls_mod.vip_plot(threshold=self.VIP_threshold).write_html(path['VIP_score_plot'] + name + '_VIP_score_plot.html')\n",
    "                pls_mod.vip_plot(threshold=self.VIP_threshold).write_image(path['VIP_score_plot'] + name + '_VIP_score_plot.png')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            #Permutation test\n",
    "            if self.permutation == True:\n",
    "                pls_mod.permutation_test(n_permutations=self.n_permutataion, n_jobs=self.n_jobs)\n",
    "                pls_mod.plot_hist().write_html(path['hist_plot'] + name + '_hist_plot.html')\n",
    "                pls_mod.plot_hist().write_image(path['hist_plot'] + name + '_hist_plot.png')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            #Linear regression\n",
    "            if self.linear_regression == True:\n",
    "                lin_ = lin_regression(x=X, target=y, label=y, features_name=feature_names)\n",
    "                lin_.create_dataset()\n",
    "                lin_.fit_model(adj_method='fdr_bh')\n",
    "                lin_.volcano_plot(fc_cut_off=self.FC_threshold, p_val_cut_off=self.p_val_threshold).write_html(path['Volcano_plot'] + name + '_Volcano_plot.html')\n",
    "                lin_.volcano_plot(fc_cut_off=self.FC_threshold, p_val_cut_off=self.p_val_threshold).write_image(path['Volcano_plot'] + name + '_Volcano_plot.png')\n",
    "                lin_.report().to_csv(path['Lingress_data'] + name + '_Lingress_data.csv', index=False)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return print('Model has been fitted successfully')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/iris.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop('Name', axis=1)\n",
    "groups = df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_opls_da(data=data, groups=groups, working_dir='/Users/aeiwz/Github/metbit/metbit/test').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# List of 32 different color codes in HEX format\n",
    "colors = [\n",
    "     \"#FFB6C1\", \"#FFD700\", \"#FFA07A\", \"#FA8072\", \"#F08080\", \"#E9967A\", \"#FF8C00\",\n",
    "    \"#FFA500\", \"#FFD700\", \"#DAA520\", \"#BDB76B\", \"#9ACD32\", \"#7FFF00\", \"#32CD32\",\n",
    "    \"#00FF7F\", \"#20B2AA\", \"#00CED1\", \"#AFEEEE\", \"#87CEEB\", \"#ADD8E6\", \"#B0E0E6\",\n",
    "    \"#87CEFA\", \"#4682B4\", \"#6495ED\", \"#4169E1\", \"#0000FF\", \"#191970\", \"#7B68EE\",\n",
    "    \"#8A2BE2\", \"#9932CC\", \"#BA55D3\", \"#FF69B4\"\n",
    "]\n",
    "\n",
    "# Convert HEX colors to RGB\n",
    "rgb_colors = [mcolors.to_rgb(c) for c in colors]\n",
    "\n",
    "# Create an image with the colors\n",
    "image = np.array([rgb_colors])\n",
    "\n",
    "# Plotting the colors\n",
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "ax.imshow(image.reshape(1, len(colors), 3), aspect='auto')\n",
    "ax.axis('off')  # Turn off axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "     \"#FFB6C1\", \"#FFD700\", \"#FFA07A\", \"#FA8072\", \"#F08080\", \"#E9967A\", \"#FF8C00\",\n",
    "    \"#FFA500\", \"#FFD700\", \"#DAA520\", \"#BDB76B\", \"#9ACD32\", \"#7FFF00\", \"#32CD32\",\n",
    "    \"#00FF7F\", \"#20B2AA\", \"#00CED1\", \"#AFEEEE\", \"#87CEEB\", \"#ADD8E6\", \"#B0E0E6\",\n",
    "    \"#87CEFA\", \"#4682B4\", \"#6495ED\", \"#4169E1\", \"#0000FF\", \"#191970\", \"#7B68EE\",\n",
    "    \"#8A2BE2\", \"#9932CC\", \"#BA55D3\", \"#FF69B4\"\n",
    "]\n",
    "\n",
    "import random\n",
    "\n",
    "color_map = {}\n",
    "for i in range(23):\n",
    "    color_map[i] = str(random.sample(colors, 1)).removeprefix(\"['\").removesuffix(\"']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "\n",
    "# Define the colors and their corresponding names\n",
    "colors = [\n",
    "    \"#FFB6C1\", \"#FFD700\", \"#FFA07A\", \"#FA8072\", \"#F08080\", \"#E9967A\", \"#FF8C00\",\n",
    "    \"#FFA500\", \"#FFD700\", \"#DAA520\", \"#BDB76B\", \"#9ACD32\", \"#7FFF00\", \"#32CD32\",\n",
    "    \"#00FF7F\", \"#20B2AA\", \"#00CED1\", \"#AFEEEE\", \"#87CEEB\", \"#ADD8E6\", \"#B0E0E6\",\n",
    "    \"#87CEFA\", \"#4682B4\", \"#6495ED\", \"#4169E1\", \"#0000FF\", \"#191970\", \"#7B68EE\",\n",
    "    \"#8A2BE2\", \"#9932CC\", \"#BA55D3\", \"#FF69B4\"\n",
    "]\n",
    "\n",
    "# Generate color map\n",
    "color_map = {}\n",
    "for i in range(23):\n",
    "    color_map[i] = str(random.sample(colors, 1)).removeprefix(\"['\").removesuffix(\"']\")\n",
    "\n",
    "# Plot the color map using rectangles and texts directly\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the color blocks and labels\n",
    "for i, (index, color) in enumerate(color_map.items()):\n",
    "    ax.add_patch(mpatches.Rectangle((0, i), 1, 1, color=color))\n",
    "    plt.text(0.5, i + 0.5, f\"{index}: {color}\", ha='center', va='center', fontsize=12, color=\"black\" if color not in [\"#000000\", \"#191970\"] else \"white\")\n",
    "\n",
    "# Set limits and remove axes\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, len(color_map))\n",
    "ax.axis('off')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.rand(100, 10))\n",
    "y = np.random.randint(0, 2, 100)\n",
    "n_components = 2\n",
    "\n",
    "lazy_opls_da(data, y, n_components, working_dir, permutation=False, VIP=False, linear_regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir = glob('/Users/aeiwz/Github/metbit/metbit/test/QuantumQuest 2024-06-25 11:29:53' + '/element/*/*/')\n",
    "\n",
    "#Create dictionary to store the path\n",
    "path = {}\n",
    "for i in dir:\n",
    "    path[i.split('/')[-2]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# let's create two data arrays with 80 observations\n",
    "X = np.random.rand(80, 10000)  # a 10000-feature (e.g., neural) data array\n",
    "Y = np.random.rand(80, 10)     # a 10-feature (e.g., behavioral) data array\n",
    "\n",
    "# we're going to pretend that this data is from 2 groups of 20 subjects each,\n",
    "# and that each subject participated in 2 task conditions\n",
    "groups = [20, 20]  # a list with the number of subjects in each group\n",
    "n_cond = 2         # the number of tasks or conditions\n",
    "\n",
    "# run the analysis and look at the results structure\n",
    "from pyls import behavioral_pls\n",
    "bpls = behavioral_pls(X, Y, groups=groups, n_cond=n_cond)\n",
    "bpls\n",
    "PLSResults(x_weights, y_weights, x_scores, y_scores, y_loadings, singvals, varexp, permres, \n",
    "bootres, splitres, cvres, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset for testing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(np.random.rand(500, 50000))\n",
    "class_ = pd.Series(np.random.choice(['A', 'B', 'C', 'D'], 500), name='Group')\n",
    "\n",
    "datasets = pd.concat([class_, data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datasets.iloc[:, 1:]\n",
    "col = X.columns.astype(float).to_list()\n",
    "y = datasets['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metbit import lazy_opls_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz = lazy_opls_da(data=X, groups=y, feature_names=col, working_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PLS(X=datasets.iloc[:, 1:], y=datasets['Group'], n_components=2, scale='pareto', kfold=3, estimator='opls', random_state=42)\n",
    "mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load your NMR spectra data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/aeiwz/example_data/main/dataset/Example_NMR_data.csv\")\n",
    "spectra = df.iloc[:,1:]\n",
    "ppm = spectra.columns.astype(float).to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_STOCSY import dynamic_STOCSY\n",
    "from STOCSY import STOCSY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lingress\n",
    "import metbit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lingress.plot_NMR_spec(spectra, ppm, df['Group']).median_spectra_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "dynamic_STOCSY(spectra=spectra, anchor_ppm_value=1.332, p_value_threshold=0.0001)\n",
    "t2 = time.time()\n",
    "du1 = t2-t1\n",
    "print(du1)\n",
    "\n",
    "t3 = time.time()\n",
    "STOCSY(spectra=spectra, anchor_ppm_value=1.332, p_value_threshold=0.0001)\n",
    "t4 = time.time()\n",
    "du2 = t4-t3\n",
    "print(du2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = time.time()\n",
    "STOCSY(spectra=spectra, anchor_ppm_value=1.332, p_value_threshold=0.0001)\n",
    "t4 = time.time()\n",
    "du2 = t4-t3\n",
    "print(du2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'PC1': [1,2,3,4], 'PC2': [1,2,3,4], 'Group': ['A', 'A', 'Z', 'Z']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_ = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC1  PC2 Group\n",
       "0    1    1     A\n",
       "1    2    2     A\n",
       "2    3    3     Z\n",
       "3    4    4     Z"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 1, 'M': 8, 'Z': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dict = {'A': 1, 'M': 8, 'Z':6}\n",
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If user not input color_dict then get unique of label and create color_dict\n",
    "if color_dict is not None:\n",
    "    color_dict_2 = color_dict\n",
    "else:\n",
    "    \n",
    "    import plotly.colors as plotly_colour\n",
    "\n",
    "    name_color_set = ['Plotly', 'D3', 'G10', 'T10', 'Alphabet', 'Dark24', 'Light24', 'Set1', 'Pastel1', \n",
    "                        'Dark2', 'Set2', 'Pastel2', 'Set3', 'Antique', 'Safe', 'Bold', 'Pastel', \n",
    "                        'Vivid', 'Prism']\n",
    "\n",
    "    palette = []\n",
    "    for name in name_color_set:\n",
    "        palette += getattr(plotly_colour.qualitative, name) # This is a list of colors\n",
    "\n",
    "    color_dict = {i: palette[i] for i in range(len(df_scores_['Group'].unique()))}\n",
    "\n",
    "    group_unique = df_scores_['Group'].unique()\n",
    "    color_dict_2 = {group_unique[i]: list(color_dict.values())[i] for i in range(len(group_unique))}\n",
    "\n",
    "#new color_dict to match with unique label\n",
    "#group_unique = df_scores_['Group'].unique()\n",
    "#change key of color_dict to match with unique label\n",
    "#color_dict_2 = {group_unique[i]: list(color_dict.values())[i] for i in range(len(group_unique))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': '#636EFA', 'Z': '#EF553B'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dict_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
